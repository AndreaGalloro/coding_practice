{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science Practice Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "You are given a list of strings (data) where each string is in the form “$device_id,$usage_in_minutes\" (quotes for clarity) such that $device_id contains exactly five lowercase English alphabets (’a’-’z’) and $usage_in_minutes is a positive integer between 1 and 1,440 with leading zeroes (if necessary, to make its length equal to 4). For instance, “abxyz,0010\" describes $device_id = “abxyz” and $usage_in_minutes = 10 minutes. Given data, return the $device_id with the largest value of $usage_in_minutes. You may assume that $device_id’s are distinct and $usage_in_minutes’ are distinct in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abxss'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ['abxyz,0010',\n",
    "    'abxss,1340',\n",
    "    'abcde,0241'\n",
    "]\n",
    "\n",
    "a = np.zeros((len(data), 2), dtype=object)\n",
    "i = 0\n",
    "for i in range(0,len(data)):\n",
    "    a[i,0] , a[i,1] = data[i].split(\",\")\n",
    "    a[i,1] = int(a[i,1])\n",
    "df = pd.DataFrame(a, columns = ['device_id', 'usage_min'])\n",
    "mx = max(df['usage_min'])\n",
    "df['device_id'][df['usage_min'] == mx][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What i am doing is taking the data and putting it into an array that I then converted into a dataframe. Then doing calculations on the dataframe and filtering by subsetting the dataframe.\n",
    "\n",
    "Let's do this without creating a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abxss'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_usage = 0\n",
    "id = ''\n",
    "for c in data:\n",
    "    model, usage = c.split(',')\n",
    "    if int(usage) > max_usage:\n",
    "        max_usage = int(usage)\n",
    "        id = model\n",
    "\n",
    "id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the solution is to update the max usage as you go through the data one by one. Starting by initializing the variables you are going to update in the loop, then checking if the usage is greater than your previous maximum along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Consider a function that is given an array/list A of distinct integers and an integer k (where 1 ≤ k ≤ len(A)), and returns all possible subarrays of A by removing k contiguous elements in A. That is, you wish to obtain a subarray of A by removing the first k elements in A, another subarray of A by removing the next k elements in A, and so on. For instance, when A = [2, 4, 6, 8, 10] and k = 3, you can remove [2, 4, 6] (which results in [8, 10]), [4, 6, 8] (which results in [2, 10]), or [6, 8, 10] (which results in [2, 4]). Since you are removing k elements from A, you always obtain a subarray of length (len(A) − k), and there are (len(A) − k + 1) such subarrays. In the provided code, the given function contains a buggy line of code. You are asked to find and fix one line of code so that the function will return a list of subarrays correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_k_elems(A, k):\n",
    "    n = len(A)\n",
    "    result = lambda arr, idx: arr[0:(idx - 1)] + arr[(idx + 1):n]\n",
    "    return [ result(A,i) for i in range(n - k + 1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2, 4, 6, 8, 4, 6, 8, 10], [6, 8, 10], [2, 8, 10]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = list(range(2, 11, 2))\n",
    "print(len(test))\n",
    "remove_k_elems(test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8, 10], [2, 10], [2, 4]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_k_elems_fix(A, k):\n",
    "    n = len(A)\n",
    "    result = lambda arr, idx: arr[0:idx] + arr[(idx + k):n]\n",
    "    return [ result(A,i) for i in range(n - k + 1) ]\n",
    "\n",
    "remove_k_elems_fix(test,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "Column Name | Type | Description\n",
    "------------|------|------------\n",
    "gender | string | either 'Male' or 'Female'\n",
    "decade | string | one of '1910s', '1920s', etc., up to '2010s'\n",
    "name | string | a non-empty string of a person's given name\n",
    "frequency | int64 | the number of a given name per gender and decade \n",
    "\n",
    "Complete the following query (replace the blank ··· with your answer) so that the query results will produce a table that contains one row for each decade with the most popular female name (for gender “F”) and male name (for gender “M”) during the decade in columns name_f and name_m, respectively. You can assume that the data table contains no ties for the most popular name for each gender and decade pair.\n",
    "\n",
    "```SQL\n",
    "SELECT\n",
    "    decade,\n",
    "    MAX(CASE\n",
    "        WHEN gender = 'F' THEN name ELSE '' END) AS name_f,\n",
    "    MAX(CASE\n",
    "        WHEN gender = 'M' THEN name ELSE '' END) AS name_m\n",
    "    FROM(\n",
    "        SELECT\n",
    "            decade,\n",
    "            gender,\n",
    "            name,\n",
    "            ...  AS x\n",
    "        FROM data\n",
    "    )\n",
    "    WHERE x = 1\n",
    "    GROUP BY 1\n",
    "    ORDER BY 1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT\n",
    "    decade,\n",
    "    MAX(CASE\n",
    "        WHEN gender = 'F' THEN name ELSE '' END) AS name_f,\n",
    "    MAX(CASE\n",
    "        WHEN gender = 'M' THEN name ELSE '' END) AS name_m\n",
    "    FROM(\n",
    "        SELECT\n",
    "            decade,\n",
    "            gender,\n",
    "            name,\n",
    "            RANK() OVER (PARTITION BY decade, gender ORDER BY frequency DESC)  AS x\n",
    "        FROM data\n",
    "    )\n",
    "    WHERE x = 1\n",
    "    GROUP BY 1\n",
    "    ORDER BY 1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a ranking that resets every time it encounters a new decade and gender, where the ranking is based on the frequency of babies, with the highest frequency being the lowest rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "You are analysing the effectiveness of a tutorial used in your statistics class. You asked n students to take a standardised test before starting the tutorial and to take another test after completing the tutorial. A valid score from this test ranges from 300 to 500, inclusive. However, due to some bugs in the grading system, some of the tests were (incorrectly) graded such that scores of those tests were increased by a factor of two (i.e., they range from 600 to 1,000). After correcting this error, you want to perform a t-test with the following hypotheses:\n",
    "\n",
    "* $H_0$: The average difference between before-tutorial and after-tutorial is 0\n",
    "* $H_1$: The average difference is non-zero.\n",
    "\n",
    "Complete the following code so that should_reject() returns true if the null hypothesis is rejected at the significance specified by alpha, and false otherwise. Assume that the conditions of your t-test are met (after fixing the incorrect scores). Constraints: score_before and score_after will contain the same number of elements (between 10 and 50 elements each, inclusive). Each element in score_before and score_after will be an integer between 300 and 1,000, inclusive. Alpha will be between 0.001 and 0.10, inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_reject(score_before, score_after, alpha):\n",
    "    # ...\n",
    "    return #..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_reject(score_before, score_after, alpha):\n",
    "    n = len(score_before)\n",
    "    for i in range(n):\n",
    "        if score_before[i] >= 600:\n",
    "            score_before[i] = score_before[i]//2\n",
    "        elif score_after[i] >= 600:\n",
    "            score_after[i] = score_after[i]//2\n",
    "    tstat, p = stats.ttest_rel(score_before, score_after)\n",
    "    return p < alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is probably a more concise way to do this, probably with vecorization, but my first instinct is that we need to correct the doubling error, so we go through the scores and check if they are greater than 600, if they are divide them by 2, we want the result to still be an integer, so we'll floor divide. Then we can use the `ttest_rel` function from the scipy package to run a two-sided ttest, then check the p-value against `alpha`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, the solution provided uses the `map` function, which applies a function to each element in a list. That solution is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_reject(score_before, score_after, alpha):\n",
    "    corrector = lambda x : x if x <= 500 else x//2\n",
    "    s0, s1 = list(map(corrector, score_before)), list(map(corrector, score_after))\n",
    "    return stats.ttest_rel(s0, s1).pvalue < alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what did I learn from this. One, I had forgotten about the `map` function, which is ridiculously helpful! Do not apply an operation to an itterable with a for loop anymore! You can just write a $\\lambda$ function and map it to the itterable! Although, keep in mind that the `map` function returns a \"map object\", which you have to run through a function like `list()` to get a specific type of object. Second, if a function returns multiple values, you can extract a specific one by typing `.outputname` after the funciton call. Lastly, if the function needs to return a `True` or `False` value, you don't need to explicitly tell it to return true or false based on a if/else statement. Just have it return the result of the boolean operation you are doing to check wich case you're in.\n",
    "\n",
    "i.e. instead of using\n",
    "\n",
    "```python\n",
    "if a < b:\n",
    "    return True\n",
    "else\n",
    "    return False\n",
    "```\n",
    "you should just write\n",
    "\n",
    "```python\n",
    "return a < b\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test\n",
    "should_reject([300, 750], [800, 400 ], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x25e2672a590>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrector = lambda x : x if x <= 500 else x//2\n",
    "map(corrector, [300, 750])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "Consider a real-value independent variable A and real value dependent variable B. You wish to model the relationship between A and B using linear regression and compute the mean squared error of the said model using the leave-one-out validation method. Write a function that returns the mean squared error of the linear regression model, given n observed values of A and B as obs_A and obs_B. Assume that both obs_A and obs_B contain exactly n elements each.\n",
    "\n",
    "Example function call\n",
    "\n",
    "```python\n",
    "linear_regression_loo(3, [0, 2, 3], [1, 2, 1])\n",
    "```\n",
    "\n",
    "Expected Output: 4.0833333333\n",
    "\n",
    "You may import and use any of sklearn, numpy, and pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_loo(n, A, B):\n",
    "    return #probably something from sklearn\n",
    "\n",
    "# test \n",
    "linear_regression_loo(3, [0,2,3], [1,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to skip this one, since I don't think a question like this will come up on the CodeSignal assessment. I don't think the interviewer ever mentioned sklearn when asking about my ability, just numpy and pandas. Although this may be helpful to learn, My time crunch means that I can't spend too much time thinking about this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc27b5ea16c50597207fc41a8e29023354377bb996637c8acdb6a50256c3f870"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
